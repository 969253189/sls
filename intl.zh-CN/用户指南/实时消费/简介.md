# 简介 {#concept_c34_tnq_zdb .concept}

数据收集至日志服务 LogHub 后，有三种方法可以处理日志：

|方式|场景|实时性|存储时间|
|:-|:-|:--|:---|
|实时消费（LogHub）|流计算、实时计算等|实时|自定义|
|索引查询（LogSearch）|适合最近热数据的在线查询|实时（99.9% 1秒，最大3秒\)|自定义|
|投递存储（LogShipper）|适合全量存储日志，进行离线分析|5~30分钟|依赖于存储系统|

## 实时消费 {#section_xjl_hdc_ry .section}

在写入日志后，最基本功能就是如何消费日志（消费日志与查询日志都意味着“读取”日志）。对于一个 Shard 中日志，消费过程如下：

1.  根据时间、Begin、End 等条件获得游标。
2.  通过游标、步长参数读取日志，同时返回下一个位置游标。
3.  不断移动游标进行日志消费。

除最基本的 API 外，日志服务提供 SDK、Storm Spout、Spark Client、Web Console 等方式进行日志消费：

-   使用[Spark Streaming Client](intl.zh-CN/用户指南/实时消费/Spark Streaming消费.md)。
-   使用[Storm Spout](intl.zh-CN/用户指南/实时消费/Storm消费.md)。
-   使用[Flink Connector](intl.zh-CN/用户指南/实时消费/Flink 消费.md)：包含Flink Consumer & Producer。
-   使用[LogHub Consumer Library](intl.zh-CN/用户指南/实时消费/消费组消费/通过消费组消费日志.md)是对LogHub消费者提供的高级模式。它提供了一个轻量级计算框架，解决多个消费者同时消费Logstore时自动分配Shard以及保序的问题。
-   使用[SDK消费日志](../../../../../intl.zh-CN/SDK 参考/基本介绍/概述.md)：日志服务提供多种语言（Java 和 Python）的 SDK，且这些语言的SDK都支持日志消费接口。关于SDK的更多信息请参考 [日志服务 SDK](../../../../../intl.zh-CN/SDK 参考/基本介绍/概述.md)。
-   使用云产品消费日志：
    -   [使用 CloudMonitor 云监控消费](intl.zh-CN/用户指南/实时消费/CloudMonitor消费.md)：监控场景。
    -   使用 E-MapReduce 消费日志：参见[Storm](intl.zh-CN/用户指南/实时消费/Storm消费.md)，[Spark Streaming](intl.zh-CN/用户指南/实时消费/Spark Streaming消费.md)。
    -   使用[命令行工具CLI](http://aliyun-log-cli.readthedocs.io/en/latest/tutorials/tutorial_pull_logs.html)消费日志。

## 查询分析 {#section_jrv_ldc_ry .section}

参见[实时查询分析简介](intl.zh-CN/用户指南/查询与分析/简介.md)：

-   使用日志服务控制台查询日志：参见[实时查询分析简介](intl.zh-CN/用户指南/查询与分析/简介.md)。
-   使用日志服务 SDK/API 查询日志：日志服务提供 REST 风格的 API，基于 HTTP 协议实现。日志服务的 API 同样提供全功能的日志查询接口。详细内容请参考[日志服务 API](../../../../../intl.zh-CN/API 参考/概览.md)。

## 投递存储 {#section_hzp_ndc_ry .section}

-   [投递日志到OSS](intl.zh-CN/用户指南/数据投递/投递日志到OSS/投递流程.md)：长时间存储或使用 E-MapReduce 分析日志。
-   [使用函数计算进行自定义投递](intl.zh-CN/用户指南/实时消费/函数计算消费/配置函数计算消费日志.md)。

## 其他 {#section_qlf_pdc_ry .section}

安全日志服务：日志服务与安全云产品对接，可通过 ISV 消费云产品日志。

